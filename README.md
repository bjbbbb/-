Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability

This project introduces an innovative approach to enhancing the robustness and reliability of deep learning models, particularly for high-risk applications. By integrating adversarial training with Conformal Prediction (CP), we formulate a bi-level optimization framework where an attacker and a defender engage in a strategic battle to respectively maximize and minimize model uncertainty.

If you find our article helpful to you, please cite the following article:

@inproceedings{jie2024Enhancing,
  title={Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability},\\
  year={2024},\\
  author={Bao, Jie and Zhang, Hanwei and Zhou Zhixin and Dang, Chuangyin and Luo Rui},\\
  booktitle={Fifty-Two International Conference on Machine Learning}\\
}
